{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "import matplotlib.dates as md\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "my_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()\n",
    "\n",
    "Limpieza_Clicks = '\"{}\"'.format(os.path.join(current_folder, '..', 'Notebook_limpieza', 'Limpieza_Clicks.ipynb'))\n",
    "Limpieza_Auctions = '\"{}\"'.format(os.path.join(current_folder, '..', 'Notebook_limpieza', 'Limpieza_Auctions.ipynb'))\n",
    "Limpieza_Installs = '\"{}\"'.format(os.path.join(current_folder, '..', 'Notebook_limpieza', 'Limpieza_Installs.ipynb'))\n",
    "Limpieza_Events = '\"{}\"'.format(os.path.join(current_folder, '..', 'Notebook_limpieza', 'Limpieza_Events.ipynb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $Limpieza_Clicks\n",
    "%run $Limpieza_Auctions\n",
    "%run $Limpieza_Installs\n",
    "%run $Limpieza_Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo del St"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el tiempo hasta que un dispositivo vuelva a aparecer en una subasta RTB como la fecha de la primera aparición en la ventana menos la fecha de inicio de la ventana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_subastas = auctions\n",
    "training_set_subastas.sort_values(ascending=True,by='date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos el set de datos de subastas en \"ventanas\" de 3 días cada una.\n",
    "ventana1_subastas = training_set_subastas.loc[(training_set_subastas['date'] > pd.to_datetime('2019-04-18')) & (training_set_subastas['date'] < pd.to_datetime('2019-04-21'))]\n",
    "ventana2_subastas = training_set_subastas.loc[(training_set_subastas['date'] > pd.to_datetime('2019-04-19')) & (training_set_subastas['date'] < pd.to_datetime('2019-04-22'))]\n",
    "ventana3_subastas = training_set_subastas.loc[(training_set_subastas['date'] > pd.to_datetime('2019-04-20')) & (training_set_subastas['date'] < pd.to_datetime('2019-04-23'))]\n",
    "ventana4_subastas = training_set_subastas.loc[(training_set_subastas['date'] > pd.to_datetime('2019-04-21')) & (training_set_subastas['date'] < pd.to_datetime('2019-04-24'))]\n",
    "ventana5_subastas = training_set_subastas.loc[(training_set_subastas['date'] > pd.to_datetime('2019-04-22')) & (training_set_subastas['date'] < pd.to_datetime('2019-04-25'))]\n",
    "ventana6_subastas = training_set_subastas.loc[(training_set_subastas['date'] > pd.to_datetime('2019-04-23')) & (training_set_subastas['date'] < pd.to_datetime('2019-04-26'))]\n",
    "ventana7_subastas = training_set_subastas.loc[(training_set_subastas['date'] > pd.to_datetime('2019-04-24')) & (training_set_subastas['date'] < pd.to_datetime('2019-04-27'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_iv1 = pd.to_datetime('2019-04-18')\n",
    "fecha_iv2 = pd.to_datetime('2019-04-19')\n",
    "fecha_iv3 = pd.to_datetime('2019-04-20')\n",
    "fecha_iv4 = pd.to_datetime('2019-04-21')\n",
    "fecha_iv5 = pd.to_datetime('2019-04-22')\n",
    "fecha_iv6 = pd.to_datetime('2019-04-23')\n",
    "fecha_iv7 = pd.to_datetime('2019-04-24')\n",
    "\n",
    "ventana1_subastas['st'] = (ventana1_subastas.groupby('device_id')['date'].transform(min) -  fecha_iv1).dt.total_seconds()\n",
    "ventana2_subastas['st'] = (ventana2_subastas.groupby('device_id')['date'].transform(min) -  fecha_iv2).dt.total_seconds()\n",
    "ventana3_subastas['st'] = (ventana3_subastas.groupby('device_id')['date'].transform(min) -  fecha_iv3).dt.total_seconds()\n",
    "ventana4_subastas['st'] = (ventana4_subastas.groupby('device_id')['date'].transform(min) -  fecha_iv4).dt.total_seconds()\n",
    "ventana5_subastas['st'] = (ventana5_subastas.groupby('device_id')['date'].transform(min) -  fecha_iv5).dt.total_seconds()\n",
    "ventana6_subastas['st'] = (ventana6_subastas.groupby('device_id')['date'].transform(min) -  fecha_iv6).dt.total_seconds()\n",
    "ventana7_subastas['st'] = (ventana7_subastas.groupby('device_id')['date'].transform(min) -  fecha_iv7).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = ventana1_subastas[['device_id','st']].drop_duplicates()\n",
    "label2 = ventana2_subastas[['device_id','st']].drop_duplicates()\n",
    "label3 = ventana3_subastas[['device_id','st']].drop_duplicates()\n",
    "label4 = ventana4_subastas[['device_id','st']].drop_duplicates()\n",
    "label5 = ventana5_subastas[['device_id','st']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo del Sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma que con St, calculamos el tiempo hasta que un dispositivo vuelva a instalar como la fecha de la primera aparición en la ventana menos la fecha de inicio de la ventana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_instalaciones = installs\n",
    "training_set_instalaciones.sort_values(ascending=True,by='created',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos el set de datos de instalaciones en \"ventanas\" de 3 días cada una.\n",
    "ventana1_instalaciones = training_set_instalaciones.loc[(training_set_instalaciones['created'] > pd.to_datetime('2019-04-18')) & (training_set_instalaciones['created'] < pd.to_datetime('2019-04-21'))]\n",
    "ventana2_instalaciones = training_set_instalaciones.loc[(training_set_instalaciones['created'] > pd.to_datetime('2019-04-19')) & (training_set_instalaciones['created'] < pd.to_datetime('2019-04-22'))]\n",
    "ventana3_instalaciones = training_set_instalaciones.loc[(training_set_instalaciones['created'] > pd.to_datetime('2019-04-20')) & (training_set_instalaciones['created'] < pd.to_datetime('2019-04-23'))]\n",
    "ventana4_instalaciones = training_set_instalaciones.loc[(training_set_instalaciones['created'] > pd.to_datetime('2019-04-21')) & (training_set_instalaciones['created'] < pd.to_datetime('2019-04-24'))]\n",
    "ventana5_instalaciones = training_set_instalaciones.loc[(training_set_instalaciones['created'] > pd.to_datetime('2019-04-22')) & (training_set_instalaciones['created'] < pd.to_datetime('2019-04-25'))]\n",
    "ventana6_instalaciones = training_set_instalaciones.loc[(training_set_instalaciones['created'] > pd.to_datetime('2019-04-23')) & (training_set_instalaciones['created'] < pd.to_datetime('2019-04-26'))]\n",
    "ventana7_instalaciones = training_set_instalaciones.loc[(training_set_instalaciones['created'] > pd.to_datetime('2019-04-24')) & (training_set_instalaciones['created'] < pd.to_datetime('2019-04-27'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventana1_instalaciones['sc'] = (ventana1_instalaciones.groupby('ref_hash')['created'].transform(min) -  fecha_iv1).dt.total_seconds()\n",
    "ventana2_instalaciones['sc'] = (ventana2_instalaciones.groupby('ref_hash')['created'].transform(min) -  fecha_iv2).dt.total_seconds()\n",
    "ventana3_instalaciones['sc'] = (ventana3_instalaciones.groupby('ref_hash')['created'].transform(min) -  fecha_iv3).dt.total_seconds()\n",
    "ventana4_instalaciones['sc'] = (ventana4_instalaciones.groupby('ref_hash')['created'].transform(min) -  fecha_iv4).dt.total_seconds()\n",
    "ventana5_instalaciones['sc'] = (ventana5_instalaciones.groupby('ref_hash')['created'].transform(min) -  fecha_iv5).dt.total_seconds()\n",
    "ventana6_instalaciones['sc'] = (ventana6_instalaciones.groupby('ref_hash')['created'].transform(min) -  fecha_iv6).dt.total_seconds()\n",
    "ventana7_instalaciones['sc'] = (ventana7_instalaciones.groupby('ref_hash')['created'].transform(min) -  fecha_iv7).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = pd.merge(label1,ventana1_instalaciones[['ref_hash','sc']].drop_duplicates(),left_on='device_id',right_on='ref_hash',how='outer')  \n",
    "del label1['ref_hash']\n",
    "label2 = pd.merge(label2,ventana2_instalaciones[['ref_hash','sc']].drop_duplicates(),left_on='device_id',right_on='ref_hash',how='outer')  \n",
    "del label2['ref_hash']\n",
    "label3 = pd.merge(label3,ventana3_instalaciones[['ref_hash','sc']].drop_duplicates(),left_on='device_id',right_on='ref_hash',how='outer')  \n",
    "del label3['ref_hash']\n",
    "label4 = pd.merge(label4,ventana4_instalaciones[['ref_hash','sc']].drop_duplicates(),left_on='device_id',right_on='ref_hash',how='outer')  \n",
    "del label4['ref_hash']\n",
    "label5 = pd.merge(label5,ventana5_instalaciones[['ref_hash','sc']].drop_duplicates(),left_on='device_id',right_on='ref_hash',how='outer')  \n",
    "del label5['ref_hash']\n",
    "\n",
    "tiempo_maximo = 259200\n",
    "label1.fillna(value=tiempo_maximo,inplace=True)\n",
    "label2.fillna(value=tiempo_maximo,inplace=True)\n",
    "label3.fillna(value=tiempo_maximo,inplace=True)\n",
    "label4.fillna(value=tiempo_maximo,inplace=True)\n",
    "label5.fillna(value=tiempo_maximo,inplace=True)\n",
    "\n",
    "labels = [label1,label2,label3,label4,label5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los label por ventana quedan de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>st</th>\n",
       "      <th>sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.826644e+18</td>\n",
       "      <td>0.015050</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.037174e+18</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.392065e+18</td>\n",
       "      <td>0.057540</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.228982e+18</td>\n",
       "      <td>0.126828</td>\n",
       "      <td>259200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.123059e+18</td>\n",
       "      <td>0.132510</td>\n",
       "      <td>17800.664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      device_id        st          sc\n",
       "0  1.826644e+18  0.015050  259200.000\n",
       "1  7.037174e+18  0.029014  259200.000\n",
       "2  3.392065e+18  0.057540  259200.000\n",
       "3  1.228982e+18  0.126828  259200.000\n",
       "4  4.123059e+18  0.132510   17800.664"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES\n",
    "Creamos features en base a los datasets. Los features van a estar divididos por dispositivo para poder mergearlos en un unico dataframe con features de todos los dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features de Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions_v1 = auctions.loc[(auctions['date'] > pd.to_datetime('2019-04-18')) & (auctions['date'] < pd.to_datetime('2019-04-21'))]\n",
    "auctions_v2 = auctions.loc[(auctions['date'] > pd.to_datetime('2019-04-19')) & (auctions['date'] < pd.to_datetime('2019-04-22'))]\n",
    "auctions_v3 = auctions.loc[(auctions['date'] > pd.to_datetime('2019-04-20')) & (auctions['date'] < pd.to_datetime('2019-04-23'))]\n",
    "auctions_v4 = auctions.loc[(auctions['date'] > pd.to_datetime('2019-04-21')) & (auctions['date'] < pd.to_datetime('2019-04-24'))]\n",
    "auctions_v5 = auctions.loc[(auctions['date'] > pd.to_datetime('2019-04-22')) & (auctions['date'] < pd.to_datetime('2019-04-25'))]\n",
    "\n",
    "ventanas_auctions = [auctions_v1, auctions_v2, auctions_v3, auctions_v4, auctions_v5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_auctions = []\n",
    "\n",
    "for ventana in ventanas_auctions:\n",
    "    features_ventana = ventana.groupby('device_id').agg({'device_id':'size'})\n",
    "    features_ventana.columns = ['cantidad_de_subastas_en_ventana']\n",
    "    features_auctions.append(features_ventana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Week_Day = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "\n",
    "for index, ventana in enumerate(ventanas_auctions):\n",
    "    for dia in Week_Day:\n",
    "        subastas_por_dia = ventana[ventana['date'].dt.day_name() == dia].groupby('device_id').agg({'device_id':'size'})\n",
    "        subastas_por_dia.columns = ['cantidad_subastas_{}'.format(dia)]\n",
    "        \n",
    "        features_auctions[index] = features_auctions[index].merge(subastas_por_dia, how='outer', left_index=True, right_index=True)\n",
    "        features_auctions[index].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features de Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_v1 = events.loc[(events['date'] >= pd.to_datetime('2019-04-18')) & (events['date'] <= pd.to_datetime('2019-04-21'))]\n",
    "events_v2 = events.loc[(events['date'] >= pd.to_datetime('2019-04-19')) & (events['date'] <= pd.to_datetime('2019-04-22'))]\n",
    "events_v3 = events.loc[(events['date'] >= pd.to_datetime('2019-04-20')) & (events['date'] <= pd.to_datetime('2019-04-23'))]\n",
    "events_v4 = events.loc[(events['date'] >= pd.to_datetime('2019-04-21')) & (events['date'] <= pd.to_datetime('2019-04-24'))]\n",
    "events_v5 = events.loc[(events['date'] >= pd.to_datetime('2019-04-22')) & (events['date'] <= pd.to_datetime('2019-04-25'))]\n",
    "\n",
    "ventanas_events = [events_v1, events_v2, events_v3, events_v4, events_v5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_events = []\n",
    "\n",
    "for ventana in ventanas_events:\n",
    "    features_ventana = ventana.groupby('ref_hash').agg({'ref_hash':'size',\n",
    "                                                        'event_id':lambda x: (x.mode())[0],\n",
    "                                                        'application_id':lambda x: (x.mode())[0]})\n",
    "    features_ventana.columns = ['cantidad_de_eventos_en_ventana','evento_mas_frecuente','aplicacion_mas_usada']\n",
    "    features_events.append(features_ventana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ventana in enumerate(ventanas_events):\n",
    "    for dia in Week_Day:\n",
    "        eventos_por_dia = ventana[ventana['date'].dt.day_name() == dia].groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "        eventos_por_dia.columns = ['cantidad_eventos_{}'.format(dia)]\n",
    "        \n",
    "        features_events[index] = features_events[index].merge(eventos_por_dia, how='outer', left_index=True, right_index=True)\n",
    "        features_events[index].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eventos por hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ventana in enumerate(ventanas_events):\n",
    "    for hora in range(24):\n",
    "        eventos_por_hora = ventana[ventana['date'].dt.hour == hora].groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "        eventos_por_hora.columns = ['cantidad_eventos_hora_{}'.format(hora)]\n",
    "        features_events[index] = features_events[index].merge(eventos_por_hora, how='outer', left_index=True, right_index=True) \n",
    "        features_events[index]['cantidad_eventos_hora_{}'.format(hora)].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrego la version más tipica de SO registrada en los eventos para cada dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,ventana in enumerate(ventanas_events):\n",
    "    ventana_temp = ventana\n",
    "    ventana_temp['device_os_version'] = ventana_temp['device_os_version'].fillna(value=0)\n",
    "    features_events[index] = features_events[index].merge(ventana_temp.groupby('ref_hash').\\\n",
    "                                              agg({'device_os_version':lambda x: (x.mode())[0]}),\n",
    "                                      left_index=True,\n",
    "                                      right_index=True,\n",
    "                                      how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hay clicks que suceden fuera del período de análisis.\n",
    "clicks_a_considerar = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-18')) & (clicks['created'] < pd.to_datetime('2019-04-27'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_v1 = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-18')) & (clicks['created'] < pd.to_datetime('2019-04-21'))]\n",
    "clicks_v2 = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-19')) & (clicks['created'] < pd.to_datetime('2019-04-22'))]\n",
    "clicks_v3 = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-20')) & (clicks['created'] < pd.to_datetime('2019-04-23'))]\n",
    "clicks_v4 = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-21')) & (clicks['created'] < pd.to_datetime('2019-04-24'))]\n",
    "clicks_v5 = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-22')) & (clicks['created'] < pd.to_datetime('2019-04-25'))]\n",
    "\n",
    "ventanas_clicks = [clicks_v1, clicks_v2, clicks_v3, clicks_v4, clicks_v5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_clicks = []\n",
    "\n",
    "for ventana in ventanas_clicks:\n",
    "    features_ventana = ventana.groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "    features_ventana.columns = ['cantidad_de_clicks_en_ventana']\n",
    "    features_clicks.append(features_ventana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ventana in enumerate(ventanas_clicks):\n",
    "    for dia in Week_Day:\n",
    "        clicks_por_dia = ventana[ventana['created'].dt.day_name() == dia].groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "        clicks_por_dia.columns = ['cantidad_clicks_{}'.format(dia)]\n",
    "        \n",
    "        features_clicks[index] = features_clicks[index].merge(clicks_por_dia, how='outer', left_index=True, right_index=True)\n",
    "        features_clicks[index].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region en pantalla del click"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se divide en una cuadricula de 9 sectores.Por un lado: Superior, subdividido en izquierda, centro y derecha; Centro con mismas subdivisiones e Inferior también con mismas subdivisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ventana in enumerate(ventanas_clicks):\n",
    "    ventana_temp = ventana[['ref_hash','touchX','touchY']].fillna(value=-1).groupby('ref_hash')\\\n",
    "                        .agg({'touchX':lambda x: (x.mode())[0],\n",
    "                              'touchY':lambda x: (x.mode())[0]}).reset_index()\n",
    "    ventana_temp['SUP_D'] = 0\n",
    "    ventana_temp['SUP_C'] = 0\n",
    "    ventana_temp['SUP_I'] = 0\n",
    "    ventana_temp['CENT_D'] = 0\n",
    "    ventana_temp['CENT_C'] = 0\n",
    "    ventana_temp['CENT_I'] = 0\n",
    "    ventana_temp['INF_D'] = 0\n",
    "    ventana_temp['INF_C'] = 0\n",
    "    ventana_temp['INF_I'] = 0\n",
    "    ventana_temp.loc[(ventana_temp['touchX']>=0.66)&(ventana_temp['touchY']>=10.66),'SUP_D'] = 1\n",
    "    ventana_temp.loc[(ventana_temp['touchX']<0.66)&(ventana_temp['touchX']>=0.33)&(ventana_temp['touchY']>=10.66),'SUP_C'] = 1\n",
    "    ventana_temp.loc[(ventana_temp['touchX']<0.33)&(ventana_temp['touchX']>=0)&(ventana_temp['touchY']>=10.66),'SUP_I'] = 1\n",
    "    ventana_temp.loc[(ventana_temp['touchX']>=0.66)&(ventana_temp['touchY']>=5.33)&(ventana_temp['touchY']<10.66),'CENT_D'] = 1\n",
    "    ventana_temp.loc[(ventana_temp['touchX']<0.66)&(ventana_temp['touchX']>=0.33)&(ventana_temp['touchY']>=5.33)&(ventana_temp['touchY']<10.66),'CENT_C'] = 1\n",
    "    ventana_temp.loc[(ventana_temp['touchX']<0.33)&(ventana_temp['touchX']>=0)&(ventana_temp['touchY']>=5.33)&(ventana_temp['touchY']<10.66),'CENT_I'] = 1\n",
    "    ventana_temp.loc[(ventana_temp['touchX']>=0.66)&(ventana_temp['touchY']>=0)&(ventana_temp['touchY']<5.33),'INF_D'] = 1\n",
    "    ventana_temp.loc[(ventana_temp['touchX']<0.66)&(ventana_temp['touchX']>=0.33)&(ventana_temp['touchY']>=0)&(ventana_temp['touchY']<5.33),'INF_C'] = 1\n",
    "    ventana_temp.loc[(ventana_temp['touchX']<0.33)&(ventana_temp['touchX']>=0)&(ventana_temp['touchY']>=0)&(ventana_temp['touchY']<5.33),'INF_I'] = 1\n",
    "    \n",
    "    #Me quedo con la region mas común para cada dispositivo\n",
    "    #mergeo con features de clicks\n",
    "    features_clicks[index] = pd.merge(features_clicks[index].reset_index(),\\\n",
    "            ventana_temp[['ref_hash','SUP_D','SUP_C','SUP_I','CENT_D','CENT_C','CENT_I','INF_D','INF_C','INF_I']].drop_duplicates(),\\\n",
    "                              on='ref_hash',how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs_v1 = installs.loc[(installs['created'] > pd.to_datetime('2019-04-18')) & (installs['created'] < pd.to_datetime('2019-04-21'))]\n",
    "installs_v2 = installs.loc[(installs['created'] > pd.to_datetime('2019-04-19')) & (installs['created'] < pd.to_datetime('2019-04-22'))]\n",
    "installs_v3 = installs.loc[(installs['created'] > pd.to_datetime('2019-04-20')) & (installs['created'] < pd.to_datetime('2019-04-23'))]\n",
    "installs_v4 = installs.loc[(installs['created'] > pd.to_datetime('2019-04-21')) & (installs['created'] < pd.to_datetime('2019-04-24'))]\n",
    "installs_v5 = installs.loc[(installs['created'] > pd.to_datetime('2019-04-22')) & (installs['created'] < pd.to_datetime('2019-04-25'))]\n",
    "\n",
    "ventanas_installs = [installs_v1, installs_v2, installs_v3, installs_v4, installs_v5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_installs = []\n",
    "\n",
    "for ventana in ventanas_installs:\n",
    "    features_ventana = ventana.groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "    features_ventana.columns = ['cantidad_de_instalaciones_en_ventana']\n",
    "    features_installs.append(features_ventana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ventana in enumerate(ventanas_installs):\n",
    "    for dia in Week_Day:\n",
    "        instalaciones_por_dia = ventana[ventana['created'].dt.day_name() == dia].groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "        instalaciones_por_dia.columns = ['cantidad_instalaciones_{}'.format(dia)]\n",
    "        \n",
    "        features_installs[index] = features_installs[index].merge(instalaciones_por_dia, how='outer', left_index=True, right_index=True)\n",
    "        features_installs[index].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrego relacion cant_instalacions/cant_eventos por dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    feature_porc = pd.merge(ventanas_events[i].groupby('ref_hash').size().reset_index(name='cantidad_eventos_x_dev'),\n",
    "                       ventanas_installs[i].groupby('ref_hash').size().reset_index(name='cantidad_inst_x_dev'),\n",
    "                       on='ref_hash',\n",
    "                       how='inner')\n",
    "    feature_porc['Porc_I-E'] =  feature_porc['cantidad_inst_x_dev'] / feature_porc['cantidad_eventos_x_dev']\n",
    "    feature_porc.set_index('ref_hash',inplace=True)\n",
    "    del feature_porc['cantidad_inst_x_dev'] \n",
    "    del feature_porc['cantidad_eventos_x_dev']\n",
    "    features_installs[i] = features_installs[i].merge(feature_porc, how='outer', left_index=True, right_index=True)\n",
    "    features_installs[i].fillna(0, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mergeo todos los features por dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasamos a float los device_id para poder joinear con los features\n",
    "for i in range(0,5):\n",
    "    labels[i] = labels[i].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_por_ventana = []\n",
    "\n",
    "for i in range(0,5):\n",
    "    features_por_ventana.append(pd.merge(features_auctions[i].reset_index(),\\\n",
    "                       features_clicks[i].reset_index(),\\\n",
    "                       left_on='device_id',right_on='ref_hash',how='outer'))\n",
    "    features_por_ventana[i]['device_id'].fillna(features_por_ventana[i]['ref_hash'],inplace=True)\n",
    "    del features_por_ventana[i]['ref_hash']\n",
    "    features_por_ventana[i] = pd.merge(features_por_ventana[i],features_installs[i].reset_index(),\\\n",
    "                        left_on='device_id',right_on='ref_hash',how='outer')\n",
    "    features_por_ventana[i]['device_id'].fillna(features_por_ventana[i]['ref_hash'],inplace=True)\n",
    "    del features_por_ventana[i]['ref_hash']\n",
    "    features_por_ventana[i] = pd.merge(features_por_ventana[i],features_events[i].reset_index(),\\\n",
    "                                       left_on='device_id',right_on='ref_hash',how='outer')\n",
    "    features_por_ventana[i]['device_id'].fillna(features_por_ventana[i]['ref_hash'],inplace=True)\n",
    "    del features_por_ventana[i]['ref_hash']\n",
    "    features_por_ventana[i].fillna(0,inplace=True)\n",
    "    features_por_ventana[i] = features_por_ventana[i].groupby('device_id').sum().reset_index()\n",
    "    features_por_ventana[i] = pd.merge(labels[i][['device_id']],features_por_ventana[i],on='device_id',how='inner')\n",
    "    features_por_ventana[i].sort_values(by='device_id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_b = []\n",
    "\n",
    "for i in range(0,5):\n",
    "    labels[i] = (labels[i].loc[labels[i]['device_id'].isin(features_por_ventana[i]['device_id'])])[['device_id','st']]\n",
    "    labels[i]['binary'] = np.where(labels[i]['st']>=tiempo_maximo,False,True)\n",
    "    labels[i].sort_values(by='device_id',inplace=True)\n",
    "    labels_b.append(labels[i][['binary','st']].to_records(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se agrega chequeo para que los df_feautures cumplan condiciones en los algoritmos a ser usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    if (features_por_ventana[i].shape[0] != labels[i].shape[0]):\n",
    "        raise AssertionError(\"Los df_features de cada ventana tienen que tener misma \\\n",
    "                cantidad de dispositivos(mismos device_id)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
