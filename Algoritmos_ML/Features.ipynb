{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "import matplotlib.dates as md\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "my_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in locals():\n",
    "    current_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "else:\n",
    "    current_folder = os.getcwd()\n",
    "\n",
    "Limpieza_Clicks = '\"{}\"'.format(os.path.join(current_folder, '..', 'Notebook_limpieza', 'Limpieza_Clicks.ipynb'))\n",
    "Limpieza_Auctions = '\"{}\"'.format(os.path.join(current_folder, '..', 'Notebook_limpieza', 'Limpieza_Auctions.ipynb'))\n",
    "Limpieza_Installs = '\"{}\"'.format(os.path.join(current_folder, '..', 'Notebook_limpieza', 'Limpieza_Installs.ipynb'))\n",
    "Limpieza_Events = '\"{}\"'.format(os.path.join(current_folder, '..', 'Notebook_limpieza', 'Limpieza_Events.ipynb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $Limpieza_Clicks\n",
    "%run $Limpieza_Auctions\n",
    "%run $Limpieza_Installs\n",
    "%run $Limpieza_Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo del St"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = auctions\n",
    "training_set.sort_values(ascending=True,by='date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos el set de datos en \"ventanas\" de 3 días cada una.\n",
    "ventana1 = training_set.loc[(training_set['date'] > pd.to_datetime('2019-04-18')) & (training_set['date'] < pd.to_datetime('2019-04-21'))]\n",
    "ventana2 = training_set.loc[(training_set['date'] > pd.to_datetime('2019-04-19')) & (training_set['date'] < pd.to_datetime('2019-04-22'))]\n",
    "ventana3 = training_set.loc[(training_set['date'] > pd.to_datetime('2019-04-20')) & (training_set['date'] < pd.to_datetime('2019-04-23'))]\n",
    "ventana4 = training_set.loc[(training_set['date'] > pd.to_datetime('2019-04-21')) & (training_set['date'] < pd.to_datetime('2019-04-24'))]\n",
    "ventana5 = training_set.loc[(training_set['date'] > pd.to_datetime('2019-04-22')) & (training_set['date'] < pd.to_datetime('2019-04-25'))]\n",
    "ventana6 = training_set.loc[(training_set['date'] > pd.to_datetime('2019-04-23')) & (training_set['date'] < pd.to_datetime('2019-04-26'))]\n",
    "ventana7 = training_set.loc[(training_set['date'] > pd.to_datetime('2019-04-24')) & (training_set['date'] < pd.to_datetime('2019-04-27'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_iv1 = pd.to_datetime('2019-04-18')\n",
    "fecha_iv2 = pd.to_datetime('2019-04-19')\n",
    "fecha_iv3 = pd.to_datetime('2019-04-20')\n",
    "fecha_iv4 = pd.to_datetime('2019-04-21')\n",
    "fecha_iv5 = pd.to_datetime('2019-04-22')\n",
    "fecha_iv6 = pd.to_datetime('2019-04-23')\n",
    "fecha_iv7 = pd.to_datetime('2019-04-24')\n",
    "\n",
    "ventana1['st'] = (ventana1.groupby('device_id')['date'].transform(min) -  fecha_iv1).dt.total_seconds()\n",
    "ventana2['st'] = (ventana2.groupby('device_id')['date'].transform(min) -  fecha_iv2).dt.total_seconds()\n",
    "ventana3['st'] = (ventana3.groupby('device_id')['date'].transform(min) -  fecha_iv3).dt.total_seconds()\n",
    "ventana4['st'] = (ventana4.groupby('device_id')['date'].transform(min) -  fecha_iv4).dt.total_seconds()\n",
    "ventana5['st'] = (ventana5.groupby('device_id')['date'].transform(min) -  fecha_iv5).dt.total_seconds()\n",
    "ventana6['st'] = (ventana6.groupby('device_id')['date'].transform(min) -  fecha_iv6).dt.total_seconds()\n",
    "ventana7['st'] = (ventana7.groupby('device_id')['date'].transform(min) -  fecha_iv7).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = ventana1[['device_id','st']].drop_duplicates()\n",
    "label2 = ventana2[['device_id','st']].drop_duplicates()\n",
    "label3 = ventana3[['device_id','st']].drop_duplicates()\n",
    "label4 = ventana4[['device_id','st']].drop_duplicates()\n",
    "label5 = ventana5[['device_id','st']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo del Sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = installs\n",
    "training_set.sort_values(ascending=True,by='created',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos el set de datos en \"ventanas\" de 3 días cada una.\n",
    "ventana1 = training_set.loc[(training_set['created'] > pd.to_datetime('2019-04-18')) & (training_set['created'] < pd.to_datetime('2019-04-21'))]\n",
    "ventana2 = training_set.loc[(training_set['created'] > pd.to_datetime('2019-04-19')) & (training_set['created'] < pd.to_datetime('2019-04-22'))]\n",
    "ventana3 = training_set.loc[(training_set['created'] > pd.to_datetime('2019-04-20')) & (training_set['created'] < pd.to_datetime('2019-04-23'))]\n",
    "ventana4 = training_set.loc[(training_set['created'] > pd.to_datetime('2019-04-21')) & (training_set['created'] < pd.to_datetime('2019-04-24'))]\n",
    "ventana5 = training_set.loc[(training_set['created'] > pd.to_datetime('2019-04-22')) & (training_set['created'] < pd.to_datetime('2019-04-25'))]\n",
    "ventana6 = training_set.loc[(training_set['created'] > pd.to_datetime('2019-04-23')) & (training_set['created'] < pd.to_datetime('2019-04-26'))]\n",
    "ventana7 = training_set.loc[(training_set['created'] > pd.to_datetime('2019-04-24')) & (training_set['created'] < pd.to_datetime('2019-04-27'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_iv1 = pd.to_datetime('2019-04-18')\n",
    "fecha_iv2 = pd.to_datetime('2019-04-19')\n",
    "fecha_iv3 = pd.to_datetime('2019-04-20')\n",
    "fecha_iv4 = pd.to_datetime('2019-04-21')\n",
    "fecha_iv5 = pd.to_datetime('2019-04-22')\n",
    "fecha_iv6 = pd.to_datetime('2019-04-23')\n",
    "fecha_iv7 = pd.to_datetime('2019-04-24')\n",
    "\n",
    "ventana1['sc'] = (ventana1.groupby('ref_hash')['created'].transform(min) -  fecha_iv1).dt.total_seconds()\n",
    "ventana2['sc'] = (ventana2.groupby('ref_hash')['created'].transform(min) -  fecha_iv2).dt.total_seconds()\n",
    "ventana3['sc'] = (ventana3.groupby('ref_hash')['created'].transform(min) -  fecha_iv3).dt.total_seconds()\n",
    "ventana4['sc'] = (ventana4.groupby('ref_hash')['created'].transform(min) -  fecha_iv4).dt.total_seconds()\n",
    "ventana5['sc'] = (ventana5.groupby('ref_hash')['created'].transform(min) -  fecha_iv5).dt.total_seconds()\n",
    "ventana6['sc'] = (ventana6.groupby('ref_hash')['created'].transform(min) -  fecha_iv6).dt.total_seconds()\n",
    "ventana7['sc'] = (ventana7.groupby('ref_hash')['created'].transform(min) -  fecha_iv7).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = pd.merge(label1,ventana1[['ref_hash','sc']].drop_duplicates(),left_on='device_id',right_on='ref_hash',how='inner')  \n",
    "del label1['ref_hash']\n",
    "label2 = pd.merge(label2,ventana2[['ref_hash','sc']].drop_duplicates(),left_on='device_id',right_on='ref_hash',how='inner')  \n",
    "del label2['ref_hash']\n",
    "label3 = pd.merge(label3,ventana3[['ref_hash','sc']].drop_duplicates(),left_on='device_id',right_on='ref_hash',how='inner')  \n",
    "del label3['ref_hash']\n",
    "label4 = pd.merge(label4,ventana4[['ref_hash','sc']].drop_duplicates(),left_on='device_id',right_on='ref_hash',how='inner')  \n",
    "del label4['ref_hash']\n",
    "label5 = pd.merge(label5,ventana5[['ref_hash','sc']].drop_duplicates(),left_on='device_id',right_on='ref_hash',how='inner')  \n",
    "del label5['ref_hash']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES\n",
    "Creamos features en base a los datasets. Los features van a estar divididos por dispositivo para poder mergearlos en un unico dataframe con features de todos los dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features de Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions_v1 = auctions.loc[(auctions['date'] > pd.to_datetime('2019-04-18')) & (auctions['date'] < pd.to_datetime('2019-04-21'))]\n",
    "auctions_v2 = auctions.loc[(auctions['date'] > pd.to_datetime('2019-04-19')) & (auctions['date'] < pd.to_datetime('2019-04-22'))]\n",
    "auctions_v3 = auctions.loc[(auctions['date'] > pd.to_datetime('2019-04-20')) & (auctions['date'] < pd.to_datetime('2019-04-23'))]\n",
    "auctions_v4 = auctions.loc[(auctions['date'] > pd.to_datetime('2019-04-21')) & (auctions['date'] < pd.to_datetime('2019-04-24'))]\n",
    "auctions_v5 = auctions.loc[(auctions['date'] > pd.to_datetime('2019-04-22')) & (auctions['date'] < pd.to_datetime('2019-04-25'))]\n",
    "\n",
    "features_auctions_v1 = auctions_v1.groupby('device_id').agg({'device_id':'size'})\n",
    "features_auctions_v2 = auctions_v2.groupby('device_id').agg({'device_id':'size'})\n",
    "features_auctions_v3 = auctions_v3.groupby('device_id').agg({'device_id':'size'})\n",
    "features_auctions_v4 = auctions_v4.groupby('device_id').agg({'device_id':'size'})\n",
    "features_auctions_v5 = auctions_v5.groupby('device_id').agg({'device_id':'size'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_auctions_v1.columns = ['cantidad_de_subastas_en_ventana']\n",
    "features_auctions_v2.columns = ['cantidad_de_subastas_en_ventana']\n",
    "features_auctions_v3.columns = ['cantidad_de_subastas_en_ventana']\n",
    "features_auctions_v4.columns = ['cantidad_de_subastas_en_ventana']\n",
    "features_auctions_v5.columns = ['cantidad_de_subastas_en_ventana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Week_Day = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "\n",
    "for dia in Week_Day:\n",
    "    subastas_por_dia = auctions[auctions['date'].dt.day_name() == dia].groupby('device_id').agg({'device_id':'size'})\n",
    "    subastas_por_dia.columns = ['cantidad_subastas_{}'.format(dia)]\n",
    "    \n",
    "    features_auctions_v1 = features_auctions_v1.merge(subastas_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_auctions_v2 = features_auctions_v2.merge(subastas_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_auctions_v3 = features_auctions_v3.merge(subastas_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_auctions_v4 = features_auctions_v4.merge(subastas_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_auctions_v5 = features_auctions_v5.merge(subastas_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "features_auctions_v1 = features_auctions_v1.fillna(0)\n",
    "features_auctions_v2 = features_auctions_v2.fillna(0)\n",
    "features_auctions_v3 = features_auctions_v3.fillna(0)\n",
    "features_auctions_v4 = features_auctions_v4.fillna(0)\n",
    "features_auctions_v5 = features_auctions_v5.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features de Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_v1 = events.loc[(events['date'] >= pd.to_datetime('2019-04-18')) & (events['date'] <= pd.to_datetime('2019-04-21'))]\n",
    "events_v2 = events.loc[(events['date'] >= pd.to_datetime('2019-04-19')) & (events['date'] <= pd.to_datetime('2019-04-22'))]\n",
    "events_v3 = events.loc[(events['date'] >= pd.to_datetime('2019-04-20')) & (events['date'] <= pd.to_datetime('2019-04-23'))]\n",
    "events_v4 = events.loc[(events['date'] >= pd.to_datetime('2019-04-21')) & (events['date'] <= pd.to_datetime('2019-04-24'))]\n",
    "\n",
    "ventanas_events = [events_v1, events_v2, events_v3, events_v4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_events = []\n",
    "\n",
    "for ventana in ventanas_events:\n",
    "    features_ventana = ventana.groupby('ref_hash').agg({'ref_hash':'size',\n",
    "                                                        'event_id':lambda x: (x.mode())[0],\n",
    "                                                        'application_id':lambda x: (x.mode())[0]})\n",
    "    features_ventana.columns = ['cantidad_de_eventos_en_ventana','evento_mas_frecuente','aplicacion_mas_usada']\n",
    "    features_events.append(features_ventana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ventana in enumerate(ventanas_events):\n",
    "    for dia in Week_Day:\n",
    "        eventos_por_dia = ventana[ventana['date'].dt.day_name() == dia].groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "        eventos_por_dia.columns = ['cantidad_eventos_{}'.format(dia)]\n",
    "        \n",
    "        features_events[index] = features_events[index].merge(eventos_por_dia, how='outer', left_index=True, right_index=True)\n",
    "        features_events[index].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eventos por hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ventana in enumerate(ventanas_events):\n",
    "    for hora in range(24):\n",
    "        eventos_por_hora = ventana[ventana['date'].dt.hour == hora].groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "        eventos_por_hora.columns = ['cantidad_eventos_hora_{}'.format(hora)]\n",
    "        features_events[index] = features_events[index].merge(eventos_por_hora, how='outer', left_index=True, right_index=True) \n",
    "        features_events[index]['cantidad_eventos_hora_{}'.format(hora)].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hay clicks que suceden fuera del período de análisis.\n",
    "clicks_a_considerar = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-18')) & (clicks['created'] < pd.to_datetime('2019-04-27'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_v1 = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-18')) & (clicks['created'] < pd.to_datetime('2019-04-21'))]\n",
    "clicks_v2 = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-19')) & (clicks['created'] < pd.to_datetime('2019-04-22'))]\n",
    "clicks_v3 = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-20')) & (clicks['created'] < pd.to_datetime('2019-04-23'))]\n",
    "clicks_v4 = clicks.loc[(clicks['created'] > pd.to_datetime('2019-04-21')) & (clicks['created'] < pd.to_datetime('2019-04-24'))]\n",
    "\n",
    "features_clicks_v1 = clicks_v1.groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "features_clicks_v2 = clicks_v2.groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "features_clicks_v3 = clicks_v3.groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "features_clicks_v4 = clicks_v4.groupby('ref_hash').agg({'ref_hash':'size'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_clicks_v1.columns = ['cantidad_de_clicks_en_ventana']\n",
    "features_clicks_v2.columns = ['cantidad_de_clicks_en_ventana']\n",
    "features_clicks_v3.columns = ['cantidad_de_clicks_en_ventana']\n",
    "features_clicks_v4.columns = ['cantidad_de_clicks_en_ventana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dia in Week_Day:\n",
    "    clicks_por_dia = clicks_a_considerar[clicks_a_considerar['created'].dt.day_name() == dia].groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "    clicks_por_dia.columns = ['cantidad_clicks_{}'.format(dia)]\n",
    "    \n",
    "    features_clicks_v1 = features_clicks_v1.merge(clicks_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_clicks_v2 = features_clicks_v2.merge(clicks_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_clicks_v3 = features_clicks_v3.merge(clicks_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_clicks_v4 = features_clicks_v4.merge(clicks_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "features_clicks_v1 = features_clicks_v1.fillna(0)\n",
    "features_clicks_v2 = features_clicks_v2.fillna(0)\n",
    "features_clicks_v3 = features_clicks_v3.fillna(0)\n",
    "features_clicks_v4 = features_clicks_v4.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region en pantalla del click\n",
    "Se dibide en una cuadricula de 9 sectores.Por un lado: Superior, subdividido en izquierda, centro y derecha; Centro con mismas subdivisiones e Inferior también con mismas subdivisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_v1  = clicks_v1[['ref_hash','touchX','touchY']].fillna(value=-1).groupby('ref_hash')\\\n",
    "    .agg({'touchX':lambda x: (x.mode())[0],'touchY':lambda x: (x.mode())[0]}).reset_index()\n",
    "clicks_v1['SUP_D'] = 0\n",
    "clicks_v1['SUP_C'] = 0\n",
    "clicks_v1['SUP_I'] = 0\n",
    "clicks_v1['CENT_D'] = 0\n",
    "clicks_v1['CENT_C'] = 0\n",
    "clicks_v1['CENT_I'] = 0\n",
    "clicks_v1['INF_D'] = 0\n",
    "clicks_v1['INF_C'] = 0\n",
    "clicks_v1['INF_I'] = 0\n",
    "\n",
    "clicks_v1.loc[(clicks_v1['touchX']>=0.66)&(clicks_v1['touchY']>=10.66),'SUP_D'] = 1\n",
    "clicks_v1.loc[(clicks_v1['touchX']<0.66)&(clicks_v1['touchX']>=0.33)&(clicks_v1['touchY']>=10.66),'SUP_C'] = 1\n",
    "clicks_v1.loc[(clicks_v1['touchX']<0.33)&(clicks_v1['touchX']>=0)&(clicks_v1['touchY']>=10.66),'SUP_I'] = 1\n",
    "clicks_v1.loc[(clicks_v1['touchX']>=0.66)&(clicks_v1['touchY']>=5.33)&(clicks_v1['touchY']<10.66),'CENT_D'] = 1\n",
    "clicks_v1.loc[(clicks_v1['touchX']<0.66)&(clicks_v1['touchX']>=0.33)&(clicks_v1['touchY']>=5.33)&(clicks_v1['touchY']<10.66),'CENT_C'] = 1\n",
    "clicks_v1.loc[(clicks_v1['touchX']<0.33)&(clicks_v1['touchX']>=0)&(clicks_v1['touchY']>=5.33)&(clicks_v1['touchY']<10.66),'CENT_I'] = 1\n",
    "clicks_v1.loc[(clicks_v1['touchX']>=0.66)&(clicks_v1['touchY']>=0)&(clicks_v1['touchY']<5.33),'INF_D'] = 1\n",
    "clicks_v1.loc[(clicks_v1['touchX']<0.66)&(clicks_v1['touchX']>=0.33)&(clicks_v1['touchY']>=0)&(clicks_v1['touchY']<5.33),'INF_C'] = 1\n",
    "clicks_v1.loc[(clicks_v1['touchX']<0.33)&(clicks_v1['touchX']>=0)&(clicks_v1['touchY']>=0)&(clicks_v1['touchY']<5.33),'INF_I'] = 1\n",
    "\n",
    "\n",
    "clicks_v2  = clicks_v2[['ref_hash','touchX','touchY']].fillna(value=-1).groupby('ref_hash')\\\n",
    "    .agg({'touchX':lambda x: (x.mode())[0],'touchY':lambda x: (x.mode())[0]}).reset_index()\n",
    "clicks_v2['SUP_D'] = 0\n",
    "clicks_v2['SUP_C'] = 0\n",
    "clicks_v2['SUP_I'] = 0\n",
    "clicks_v2['CENT_D'] = 0\n",
    "clicks_v2['CENT_C'] = 0\n",
    "clicks_v2['CENT_I'] = 0\n",
    "clicks_v2['INF_D'] = 0\n",
    "clicks_v2['INF_C'] = 0\n",
    "clicks_v2['INF_I'] = 0\n",
    "clicks_v2.loc[(clicks_v2['touchX']>=0.66)&(clicks_v2['touchY']>=10.66),'SUP_D'] = 1\n",
    "clicks_v2.loc[(clicks_v2['touchX']<0.66)&(clicks_v2['touchX']>=0.33)&(clicks_v2['touchY']>=10.66),'SUP_C'] = 1\n",
    "clicks_v2.loc[(clicks_v2['touchX']<0.33)&(clicks_v2['touchX']>=0)&(clicks_v2['touchY']>=10.66),'SUP_I'] = 1\n",
    "clicks_v2.loc[(clicks_v2['touchX']>=0.66)&(clicks_v2['touchY']>=5.33)&(clicks_v2['touchY']<10.66),'CENT_D'] = 1\n",
    "clicks_v2.loc[(clicks_v2['touchX']<0.66)&(clicks_v2['touchX']>=0.33)&(clicks_v2['touchY']>=5.33)&(clicks_v2['touchY']<10.66),'CENT_C'] = 1\n",
    "clicks_v2.loc[(clicks_v2['touchX']<0.33)&(clicks_v2['touchX']>=0)&(clicks_v2['touchY']>=5.33)&(clicks_v2['touchY']<10.66),'CENT_I'] = 1\n",
    "clicks_v2.loc[(clicks_v2['touchX']>=0.66)&(clicks_v2['touchY']>=0)&(clicks_v2['touchY']<5.33),'INF_D'] = 1\n",
    "clicks_v2.loc[(clicks_v2['touchX']<0.66)&(clicks_v2['touchX']>=0.33)&(clicks_v2['touchY']>=0)&(clicks_v2['touchY']<5.33),'INF_C'] = 1\n",
    "clicks_v2.loc[(clicks_v2['touchX']<0.33)&(clicks_v2['touchX']>=0)&(clicks_v2['touchY']>=0)&(clicks_v2['touchY']<5.33),'INF_I'] = 1\n",
    "\n",
    "clicks_v3  = clicks_v3[['ref_hash','touchX','touchY']].fillna(value=-1).groupby('ref_hash')\\\n",
    "    .agg({'touchX':lambda x: (x.mode())[0],'touchY':lambda x: (x.mode())[0]}).reset_index()\n",
    "clicks_v3['SUP_D'] = 0\n",
    "clicks_v3['SUP_C'] = 0\n",
    "clicks_v3['SUP_I'] = 0\n",
    "clicks_v3['CENT_D'] = 0\n",
    "clicks_v3['CENT_C'] = 0\n",
    "clicks_v3['CENT_I'] = 0\n",
    "clicks_v3['INF_D'] = 0\n",
    "clicks_v3['INF_C'] = 0\n",
    "clicks_v3['INF_I'] = 0\n",
    "clicks_v3.loc[(clicks_v3['touchX']>=0.66)&(clicks_v3['touchY']>=10.66),'SUP_D'] = 1\n",
    "clicks_v3.loc[(clicks_v3['touchX']<0.66)&(clicks_v3['touchX']>=0.33)&(clicks_v3['touchY']>=10.66),'SUP_C'] = 1\n",
    "clicks_v3.loc[(clicks_v3['touchX']<0.33)&(clicks_v3['touchX']>=0)&(clicks_v3['touchY']>=10.66),'SUP_I'] = 1\n",
    "clicks_v3.loc[(clicks_v3['touchX']>=0.66)&(clicks_v3['touchY']>=5.33)&(clicks_v3['touchY']<10.66),'CENT_D'] = 1\n",
    "clicks_v3.loc[(clicks_v3['touchX']<0.66)&(clicks_v3['touchX']>=0.33)&(clicks_v3['touchY']>=5.33)&(clicks_v3['touchY']<10.66),'CENT_C'] = 1\n",
    "clicks_v3.loc[(clicks_v3['touchX']<0.33)&(clicks_v3['touchX']>=0)&(clicks_v3['touchY']>=5.33)&(clicks_v3['touchY']<10.66),'CENT_I'] = 1\n",
    "clicks_v3.loc[(clicks_v3['touchX']>=0.66)&(clicks_v3['touchY']>=0)&(clicks_v3['touchY']<5.33),'INF_D'] = 1\n",
    "clicks_v3.loc[(clicks_v3['touchX']<0.66)&(clicks_v3['touchX']>=0.33)&(clicks_v3['touchY']>=0)&(clicks_v3['touchY']<5.33),'INF_C'] = 1\n",
    "clicks_v3.loc[(clicks_v3['touchX']<0.33)&(clicks_v3['touchX']>=0)&(clicks_v3['touchY']>=0)&(clicks_v3['touchY']<5.33),'INF_I'] = 1\n",
    "\n",
    "clicks_v4  = clicks_v4[['ref_hash','touchX','touchY']].fillna(value=-1).groupby('ref_hash')\\\n",
    "    .agg({'touchX':lambda x: (x.mode())[0],'touchY':lambda x: (x.mode())[0]}).reset_index()\n",
    "clicks_v4['SUP_D'] = 0\n",
    "clicks_v4['SUP_C'] = 0\n",
    "clicks_v4['SUP_I'] = 0\n",
    "clicks_v4['CENT_D'] = 0\n",
    "clicks_v4['CENT_C'] = 0\n",
    "clicks_v4['CENT_I'] = 0\n",
    "clicks_v4['INF_D'] = 0\n",
    "clicks_v4['INF_C'] = 0\n",
    "clicks_v4['INF_I'] = 0\n",
    "clicks_v4.loc[(clicks_v4['touchX']>=0.66)&(clicks_v4['touchY']>=10.66),'SUP_D'] = 1\n",
    "clicks_v4.loc[(clicks_v4['touchX']<0.66)&(clicks_v4['touchX']>=0.33)&(clicks_v4['touchY']>=10.66),'SUP_C'] = 1\n",
    "clicks_v4.loc[(clicks_v4['touchX']<0.33)&(clicks_v4['touchX']>=0)&(clicks_v4['touchY']>=10.66),'SUP_I'] = 1\n",
    "clicks_v4.loc[(clicks_v4['touchX']>=0.66)&(clicks_v4['touchY']>=5.33)&(clicks_v4['touchY']<10.66),'CENT_D'] = 1\n",
    "clicks_v4.loc[(clicks_v4['touchX']<0.66)&(clicks_v4['touchX']>=0.33)&(clicks_v4['touchY']>=5.33)&(clicks_v4['touchY']<10.66),'CENT_C'] = 1\n",
    "clicks_v4.loc[(clicks_v4['touchX']<0.33)&(clicks_v4['touchX']>=0)&(clicks_v4['touchY']>=5.33)&(clicks_v4['touchY']<10.66),'CENT_I'] = 1\n",
    "clicks_v4.loc[(clicks_v4['touchX']>=0.66)&(clicks_v4['touchY']>=0)&(clicks_v4['touchY']<5.33),'INF_D'] = 1\n",
    "clicks_v4.loc[(clicks_v4['touchX']<0.66)&(clicks_v4['touchX']>=0.33)&(clicks_v4['touchY']>=0)&(clicks_v4['touchY']<5.33),'INF_C'] = 1\n",
    "clicks_v4.loc[(clicks_v4['touchX']<0.33)&(clicks_v4['touchX']>=0)&(clicks_v4['touchY']>=0)&(clicks_v4['touchY']<5.33),'INF_I'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me quedo con la region mas común para cada dispositivo\n",
    "# mergeo con features de clicks\n",
    "\n",
    "features_clicks_v1 = pd.merge(features_clicks_v1.reset_index(),\\\n",
    "            clicks_v1[['ref_hash','SUP_D','SUP_C','SUP_I','CENT_D','CENT_C','CENT_I','INF_D','INF_C','INF_I']].drop_duplicates(),\\\n",
    "                              on='ref_hash',how='inner')\n",
    "features_clicks_v2 = pd.merge(features_clicks_v2.reset_index(),\\\n",
    "            clicks_v2[['ref_hash','SUP_D','SUP_C','SUP_I','CENT_D','CENT_C','CENT_I','INF_D','INF_C','INF_I']].drop_duplicates(),\\\n",
    "                              on='ref_hash',how='inner')\n",
    "features_clicks_v3 = pd.merge(features_clicks_v3.reset_index(),\\\n",
    "            clicks_v3[['ref_hash','SUP_D','SUP_C','SUP_I','CENT_D','CENT_C','CENT_I','INF_D','INF_C','INF_I']].drop_duplicates(),\\\n",
    "                              on='ref_hash',how='inner')\n",
    "features_clicks_v4 = pd.merge(features_clicks_v4.reset_index(),\\\n",
    "            clicks_v4[['ref_hash','SUP_D','SUP_C','SUP_I','CENT_D','CENT_C','CENT_I','INF_D','INF_C','INF_I']].drop_duplicates(),\\\n",
    "                              on='ref_hash',how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs_v1 = installs.loc[(installs['created'] > pd.to_datetime('2019-04-18')) & (installs['created'] < pd.to_datetime('2019-04-21'))]\n",
    "installs_v2 = installs.loc[(installs['created'] > pd.to_datetime('2019-04-19')) & (installs['created'] < pd.to_datetime('2019-04-22'))]\n",
    "installs_v3 = installs.loc[(installs['created'] > pd.to_datetime('2019-04-20')) & (installs['created'] < pd.to_datetime('2019-04-23'))]\n",
    "installs_v4 = installs.loc[(installs['created'] > pd.to_datetime('2019-04-21')) & (installs['created'] < pd.to_datetime('2019-04-24'))]\n",
    "installs_v5 = installs.loc[(installs['created'] > pd.to_datetime('2019-04-22')) & (installs['created'] < pd.to_datetime('2019-04-25'))]\n",
    "\n",
    "features_installs_v1 = installs_v1.groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "features_installs_v2 = installs_v2.groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "features_installs_v3 = installs_v3.groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "features_installs_v4 = installs_v4.groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "features_installs_v5 = installs_v5.groupby('ref_hash').agg({'ref_hash':'size'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_installs_v1.columns = ['cantidad_de_instalaciones_en_ventana']\n",
    "features_installs_v2.columns = ['cantidad_de_instalaciones_en_ventana']\n",
    "features_installs_v3.columns = ['cantidad_de_instalaciones_en_ventana']\n",
    "features_installs_v4.columns = ['cantidad_de_instalaciones_en_ventana']\n",
    "features_installs_v5.columns = ['cantidad_de_instalaciones_en_ventana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dia in Week_Day:\n",
    "    instalaciones_por_dia = installs[installs['created'].dt.day_name() == dia].groupby('ref_hash').agg({'ref_hash':'size'})\n",
    "    instalaciones_por_dia.columns = ['cantidad_installs_{}'.format(dia)]\n",
    "    \n",
    "    features_installs_v1 = features_installs_v1.merge(instalaciones_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_installs_v2 = features_installs_v2.merge(instalaciones_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_installs_v3 = features_installs_v3.merge(instalaciones_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_installs_v4 = features_installs_v4.merge(instalaciones_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    features_installs_v5 = features_installs_v5.merge(instalaciones_por_dia, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "features_installs_v1 = features_installs_v1.fillna(0)\n",
    "features_installs_v2 = features_installs_v2.fillna(0)\n",
    "features_installs_v3 = features_installs_v3.fillna(0)\n",
    "features_installs_v4 = features_installs_v4.fillna(0)\n",
    "features_installs_v5 = features_installs_v5.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mergeo todos los features por dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_v1 = pd.merge(features_auctions_v1.reset_index(),\\\n",
    "                       features_clicks_v1,\\\n",
    "                       left_on='device_id',right_on='ref_hash',how='inner')\n",
    "del features_v1['device_id']\n",
    "features_v1 = pd.merge(features_v1,features_installs_v1.reset_index(),on='ref_hash',how='inner')\n",
    "features_v1 = pd.merge(features_v1,features_events[0].reset_index(),on='ref_hash',how='inner')\n",
    "features_v1 = pd.merge(label1[['device_id']],features_v1,left_on='device_id',right_on='ref_hash',how='inner')\n",
    "features_v1.sort_values(by='ref_hash',inplace=True)\n",
    "del features_v1['device_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_v2 = pd.merge(features_auctions_v2.reset_index(),\\\n",
    "                       features_clicks_v2,\\\n",
    "                       left_on='device_id',right_on='ref_hash',how='inner')\n",
    "del features_v2['device_id']\n",
    "features_v2 = pd.merge(features_v2,features_installs_v2.reset_index(),on='ref_hash',how='inner')\n",
    "features_v2 = pd.merge(features_v2,features_events[1].reset_index(),on='ref_hash',how='inner')\n",
    "features_v2 = pd.merge(label2[['device_id']],features_v2,left_on='device_id',right_on='ref_hash',how='inner')\n",
    "features_v2.sort_values(by='ref_hash',inplace=True)\n",
    "del features_v2['device_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = (label1.loc[label1['device_id'].isin(features_v1['ref_hash'])])[['device_id','st']]\n",
    "tiempo_maximo = 259200\n",
    "label1['binary'] = np.where(label1['st']>=tiempo_maximo,False,True)\n",
    "label1.sort_values(by='device_id',inplace=True)\n",
    "label1_b = label1[['binary','st']].to_records(index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2 = (label2.loc[label2['device_id'].isin(features_v2['ref_hash'])])[['device_id','st']]\n",
    "label2['binary'] = np.where(label2['st']>=tiempo_maximo,False,True)\n",
    "label2.sort_values(by='device_id',inplace=True)\n",
    "label2_b = label2[['binary','st']].to_records(index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se agrega chequeo para que los df_feautures cumplan condiciones en los algoritmos a ser usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (features_v1.shape[0] != label1.shape[0]) or \\\n",
    "    (features_v2.shape[0] != label2.shape[0]):\n",
    "    raise AssertionError(\"Los df_features de cada ventana tienen que tener misma \\\n",
    "                cantidad de dispositivos(mismos device_id)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
